# 16 자바 메모리 모델
- 책 전체에 걸쳐 자바 메모리 모델(JMM) 부분 언급 자제하고 안전한 공개, 동기화 정책을 정하고 그 정책을 따르는 방법 등과 같이 중요한 상위 개념 위주로 설명
- 하지만 상위 개념이 제공하는 안전성은 모두 JMM 기반으로 하고 있고, JMM의 내부 구조가 어떻게 동작하는지를 이해하고 있다면 상위 개념 쉽게 사용 가능
- 16장에서는 JMM이 보장하는 기능과 요구사항, 그리고 이 책 전체에서 소개했던 내용이 실제로는 어떻게 동작하는지에 대한 원리를 알아본다.

## 16.1 JMM은 무엇이며, 왜 사용해야 하는가?
- 특정 스레드에서 aVariable 이라는 변수에 값을 할당한다고 해보자 
    - aVariable = 3;
- JMM은 "스레드가 aVariable에 할당된 3이란 값을 사용할 수 있으려면 어떤 조건이 돼야 하는가?" 에 대한 답을 알고 있다.
- 만약 동기화 기법을 사용하지 않는 상태의 경우 특정 스레드가 값이 할당되는 즉시, 심지어는 영원히 3이라는 값을 읽어가지 못하게 되는 여러 상황 발생 가능
- 컴파일러에서 소스코드에 적힌 내용을 명확하게 구현하는 코드를 생성해내지 못할 가능성도 있고, 변수의 값을 메모리에 저장하는 대신 CPU의 레지스터에 보관할 수도 있다.
- CPU 프로세서는 프로그램을 순차적으로 실행하거나 또는 병렬로 실행할 수도 있고, 사용하는 캐시의 형태에 따라서 할당된 값이 메모리에 실제 보관되는 시점에 차이가 있기도 하며, CPU 내부의 캐시에 보관된 할당 값이 다른 CPU의 시야에는 보이지 않을 수도 있다.
- 이런 원인 때문에 적절한 동기화 방법을 사용하지 않았다면, 특정 스레드에서 변수에 할당된 최신 값을 읽어가지 못할 수 있으며 따라서 다른 스레드의 시각으로 보기에 이상한 방법으로 실행될 가능성이 있다.
- 단일 스레드로 동작하는 환경에서는 프로그램이 동작하면서 사용했던 여러 가지 기법이 만들어낸 결과가 숨겨져 있고, 반면 그로 인해 전체적인 프로그램의 실행 속도는 상당히 빨라진다.
- 자바 언어 명세에서는 JVM이 단일 스레드 내부에서는 순차적으로 동작하는 것과 동일하게 실행되도록 명시되고 있다.
- 프로그램이 완벽하게 순차적으로 실행되는 환경과 동일한 순서로 실행된 것처럼 같은 결과를 만들어 내주기만 한다면 여러 가지 기법을 사용해도 문제가 없다.
- 실행속도를 높이는 여러 가지 기법은 처리 속도를 높이기 위한 최근의 노력에서 중요한 위치를 차지하고 있다. 물론 CPU의 클럭 스피드가 높아진 것도 프로그램 실행 속도를 높여 주었지만, 병렬 처리 방법 역시 프로그램의 실행속도를 크게 높여줬다.
    - ex : 파이프라인 슈퍼스칼라 실행 구조라든가 동적인 명령 스케쥴링, 모험적인 실행 방법, 섬세한 다중 메모리 캐싱 등
- 하드웨어 프로세서가 고급화됨에 따라 컴파일러 역시 최적의 실행 방법을 찾아내거나 전역 레지스터 할당 알고리즘과 같은 섬세한 기능을 갖추고 있다.
- 또한 클럭 스피드를 높이는 것만으론느 적절한 가격에 원하는 만큼 속도를 높이기가 어려워지면서, 프로세서 제조 업체에서는 멀티 코어 프로세서 구조로 이동하면서 하드웨어적인 병렬 작업을 통해 속도 향상을 꾀하고 있다.
- 멀티스레드로 실행되는 환경에서는 성능을 크게 제한하지 않는 한 순차성이 주는 안전성과 높은 성능을 찾아보기 어렵다.
- 병렬 프로그램이라 하더라도 대부분의 시간은 스레드 내부에서 '각자의 작업'을 처리하기 때문에 스레드 간의 작업 조율 기능에 자원을 많이 낭비하는 일은 별 이득도 없으면서 프로그램의 성능만 떨어뜨리는 결과를 낳는다.
- 스레드 간의 작업을 조율하는데 꼭 필요한 데이터만을 공유해 사용하는 것이 올바른 방법이고, JVM은 동기화 기능을 사용하는 부분에 한해서 프로그램에 스레드 간의 조율을 하고자 한다는 점을 파악할 수 있다.
- JMM은 변수의 저장된 값이 어느 시점부터 다른 스레드의 가시권에 들어가는지에 대해 JVM이 해야만 하는 최소한의 보장만 할 뿐이다.
- JMM은 예측성에 대한 필요와 함께 높은 성능의 JVM을 다양한 종류의 프로세서 구조에서 동작하도록 해야 한다는 실제적인 요구 사항을 쉽게 구현할 수 있어야 한다는 점의 균형을 맞출 목적으로 설계됐다.
- 특히 JMM의 일부는 JVM에서 실행되는 프로그램의 성능을 최대한 끌어낼 수 있도록 최신 프로세서와 컴파일러에서 사용하는 여러 기법을 사용하고 있는데, 이런 부분에 약간 어려움이 있을 수 있다.

### 16.1.1 플랫폼 메모리 모델
- 메모리를 공유하는 멀티프로세서 시스템은 보통 각자의 프로세서 안에 캐시 메모리를 갖고 있으며, 캐시 메모리의 내용은 주기적으로 메인 메모리와 동기화도니다.
- 하드웨어 프로세서 아키텍처는 저마다 다른 캐시 일관성을 지원한다. 
- 일부 시스템에서는 어느 시점이건 간에 동일한 순간에 같은 메모리 위치에서 각 프로세서가 서로 다른 값을 읽어가는 경우를 허용하기도 한다.
- 운영체제와 컴파일러와 자바 런타임, 때로는 프로그램까지도 서로 다른 하드웨어에서 제공하는 기능과 스레드 안전성에 대한 차이점을 메울 수 있어야 한다.
- 멀티 프로세서 시스템에서 각 프로세서가 서로 다른 프로세서가 하는 일을 모두 알 수 있는건 부하가 크다.
- 대부분의 경우 다른 프로세서가 어떤 일을 하고 있는지에 대한 정보는 별로 필요도 없기 때문에 프로세서는 대부분 성능을 높이고자 캐시 메모리의 일관성을 약간씩 희생하곤 한다.
- 시스템 구조에서 말하는 메모리 모델은 프로그램이 메모리 구조에서 어느 정도의 기능을 사용할 수 있을지에 대한 정보를 제공하고, 메모리의 내용을 서로 공유하고자 할 때 프로세서 간의 작업을 조율하기 위한 특별한 명령어로는 어떤 것을이 있으며 어떻게 사용해야 하는지에 대한 정보도 제공한다.
- 자바 개발자가 서로 다른 하드웨어가 갖고 있는 각자의 메모리 모델을 직접 신경 쓰지 않도록 자바는 스스로의 메모리 모델인 JMM을 구성하고 있으며 JMM과 그 기반이 되는 하드웨어 메모리 모델의 차이점은 메모리 배리어를 적절히 활용하는 방법 등으로 JVM에서 담당해 처리한다.
- 프로그램이 실행되는 내용을 예상하기에 가장 간편한 방법은 하드웨어 프로세서에 상관 없이 프로그램 내부에 작성된 코드가 실행되는 단 한가지 방법이 존재하며 프로그램이 실행되는 과정에서 변수의 마지막으로 설정한 값을 어떤 프로세서건 간에 정확하게 읽어낼 수 있다고 가정하는 방법이다.
- 비현실적이긴 하지만 이처럼 꿈같이 간편한 상태를 순차적 일관성이라고 부른다. 
- 소프트웨어 개발자는 무의식적으로 순차적 일관성이 존재한다고 가정해버리는 경우가 많은데, 현재 사용중인 어떤 프로세서도 순차적 일관성을 지원하지 않으며 JMM 역시 지원하지 않는다.
- 역사적으로 폰 노이만 모델이라고 부르는 순차적인 실행 구조는 현대의 멀티프로세서 시스템이 동작하는 모습으로 본다면 명확하지 않게 실행 순서를 추정하는 정도에 해당될 뿐이다.
- 메모리를 공유해 사용하는 멀티 프로세서 시스템에서는 여러 스레드에서 데이터를 공유하는 상황에서 메모리 배리어를 사용하지 않도록 일부러 지정한다면 놀랄만한 문제점이 쏟아질 것이다. 
- 다행슬버게도 자바로 프로그램을 작성하는 과정에서 메모리 배리어를 어디에 어떻게 배치해야 하는지를 고민할 필요는 없다. 단지 프로그램 내부에서 동기화 기법을 적절히 활용해 어느 시점에서 공유된 정보를 사용하는지만 알려주면 된다.

### 16.1.2 재배치
- 2장에서 경쟁조건과 연산의 단일성 오류를 설명하면서 제대로 동기화되지 않는 프로그램에서 스케쥴러가 작업을 겹쳐 실행하는 바람에 잘못된 결과를 만들어내는 '운나쁜 타이밍'을 그림으로 소개했었다.
- 더군다나 JMM은 서로 다른 스레드가 각자의 상황에 맞는 순서로 명령어를 실행할 수 있도록 허용하고 있기 때문에 동기화가 돼 있지 않은 부분을 놓고 실행 순서를 예측하는 일이 훨씬 더 복잡해졌다.
- 특정 작업이 지연되거나 다른 순서로 실행되는 것처럼 보이는 문제는 '재배치' 라는 용어로 통일해서 표현한다.
- 예제 16.1의 PossibleReordering 클래스는 제대로 동기화되지 않은 상태라면 아주 간단한 병렬 프로그램조차 동작할 못브을 예측하기가 어렵다는 사실을 보여준다.
- 예제 16.1 제대로 동기화되지 않아 어이 없는 결과를 출력하기도 하는 프로그램
~~~java
public class PossibleReordering {
    static int x = 0, y = 0;
    static int a = 0, b = 0;

    public static void main(String[] args) throws InterruptedException {
        Thread one = new Thread(new Runnable() {
            @Override
            public void run() {
                a = 1;
                x = b;
            }
        });
        
        Thread other = new Thread(new Runnable() {
            @Override
            public void run() {
                b = 1;
                y = a;
            }
        });
        
        one.start();
        other.start();
        one.join();
        other.join();

        System.out.println("( " + x + ", " + y + ")");
    }
}
~~~
- PossibleReordering클래스에서 (1,0)이나 (0,1) 아니면 (1,1)의 결과 가운데 어느 것이라도 출력될 수 있다는 점은 쉽게 예측할 수 있다.
- 스레드 B가 시작하기도 전에 스레드 A의 작업이 마무리 될 수도 있고, 스레드 A가 시작하기 전에 스레드 B의 작업이 끝날 수도 있고, 아니면 두 개의 스레드가 섞여서 실행될 수도 있다.
- 이상하게 (0,0)이 출력될 수도 있다. 
- 각 스레드 내부에서 일어나는 작업은 다른 스레드와의 연결 관계까 없으며 따라서 순서가 재배치된 상태로 실행될 가능성도 있다.
- 그림 16.1을 보면 PossibleReordering 클래스에서 (0,0)을 출력하게 되는 실행 순서를 그림으로 소개하고 있다.
- ![그림 16.1 PossibleReordering클래스에서 재배ㅐ치가 나타나면서 겹쳐 실행되는 모습](/image/picture16_1.jpg)
- 그림 16.1 PossibleReordering클래스에서 재배ㅐ치가 나타나면서 겹쳐 실행되는 모습
- PossibleReordering 클래스는 굉장히 간단한 프로그램이지만 가능한 모든 결과를 예측해보는 일은 이처럼 간단한 프로그램의 경우에도 그다지 쉽지 않다.
- 메모리 수준에서의 재배치 현상은 프로그램이 오작동하게 만들기 십상이다.
- 동기화가 제대로 되지 않은 상태에서 재배치될 가능성을 예측하는 일은 너무나 어려우며 , 반대로 동기화 방법을 적절하게 사용해 재배치 가능성을 없애는 편이 더 쉽다.
- 동기화가 잘 된 상태에서는 컴파일러, 런타임, 하드웨어 모두 JMM을 보장하는 가시성 수준을 위반하는 쪽으로 메모리 관련 작업을 재배치하지 못하게 된다.

### 16.1.3 JMM을 간략하게 설명한다면
- 변수를 읽거나 쓰는 작업, 모니터를 잠그거나 해제하는 작업, 스레드를 시작하거나 끝나기를 기다리는 작업과 같이 여러 가지 작업에 대해 JMM을 정의한다.
- JMM에서는 프로그램 내부의 모든 작업을 대상으로 미리 발생이라는 부분 재배치 연산을 정의하고 있다.
- 작업 A가 실행된 결과를 작업 B에서 볼 수 있다는 점을 보장하기 위해 작업 A와 B사이에는 미리 발생 관계가 갖춰져야 한다. 
- 두 개 작업 간에 미리 발생 관계가 갖춰져 있지 않다면 JVM은 원하는 대로 해당 작업을 재배치할 수 있게 된다.
- 하나의 변수를 두 개 이상의 스레드에서 읽어가려고 하면서 최소한 하나 이상의 스레드에서 쓰기 작업을 하지만, 쓰기 작업과 읽기 작업 간에 미리 발생 관계가 갖춰져 있지 않은 경우에 데이터 경쟁 현상이 발생한다.
- 이와 같은 데이터 경쟁 현상이 발생하지 않는 프로그램을 '올바르게 동기화된 프로그램'이라고 말한다.
- 올바르게 동기화된 프로그램은 순차적 일관성을 갖고 있으며, 다시 말해 프로그램 내부의 모든 작업이 고정된 전역 순서에 따라 실행된다는 것을 의미한다.
- 미리 발생 현상에 대한 규칙
  - 프로그램 순서 규칙 : 특정 스레드를 놓고 봤을 때 프로그램된 순서에서 앞서있는 작업은 동일 스레드에서 뒤에 실행되도록 프로그램된 작업보다 미리 발생한다.
  - 모니터 잠금 규칙 : 특정 모니터 잠금 작업이 뒤이어 오는 모든 모니터 잠금 작업보다 미리 발생한다.
  - volatile 규칙 : volatile 변수에 대한 쓰기 작업은 이후에 따라오는 해당 변수에 대한 모든 읽기 작업보다 미리 발생한다.
  - 스레드 시작 규칙 : 특정 스레드에 대한 Thread.start 작업은 스레드가 갖고 있는 모든 작업보다 미리 발생한다.
  - 스레드 완료 규칙 : 스레드 내부의 모든 작업은 다른 스레드에서 해당 스레드가 완료됐다는 점을 파악하는 시점보다 미리 발생한다. 특정 스레드가 완료됐는지를 판단하는 것은 Thread.join 메소드가 리턴되거나 Thread.isAlive 메소드가 false를 리턴하는지 확인하는 방법을 말한다.
  - 인터럽트 규칙 : 다른 스레드를 대상으로 interrupt메소드를 호출하는 작업은 인터럽트 당한 스레드에서 인터럽트를 당했다는 사실을 파악하는 일보다 미리 발생한다. 인터럽트를 당했다는 사실을 파악하려면 InterruptedException을 받거나, isInerrupted 메소드 또는 interrupt 메소드를 호출하는 방법을 사용할 수 있다.
  - 완료 메소드(finalizer) 규칙 : 특정 객체에 대한 생성자가 완료되는 시점은 완료 메소드가 시작하는 시점보다 미리 발생한다.
  - 전이성 : A가 B보다 미리 발생하고, B가 C보다 미리 발생한다면 A는 C보다 미리 발생한다.
- 작업이 부분적으로만 순서가 정해져 있다고 해도, 동기화 작업은 항상 완전하게 순서가 정해진 작업이다.
- 따라서 락을 호가보한 이후에 연달아 일어나는 volatile 변수의 값을 읽는 작업에 대해 미리 발생 규칙을 저용하는 일도 충분히 가능하다.
- ![그림 16.2 자바 메모리 모델에서의 미리 발생 관계](/image/picture16_2.jpg)
- 그림 16.2 자바 메모리 모델에서의 미리 발생 관계
- 그림 16.2를 보면 일반적인 락을 사용해 동기화된 두 개의 스레드 간에 미리 발생 규칙이 적용되는 모습이 나타나 있다.
- 스레드 A와 스레드 B의 모든 작업은 프로그램 내부의 규칙에 따라 순서가 정해져 있다.
- 스레드 A에서 락M을 해제하면 스레드 B에서 해제된 락 M을 확보하며, 스레드 A에서 라긍ㄹ 해제하기 전에 하도록 돼 있던 모든 작업은 스레드 B에서 락을 확보한 이후에 실행되는 작업보다 먼저 실행되도록 순서가 정해진다.
- 두 개의 스레드가 서로 다른 락으로 동기화돼 있다면 양쪽 스레드에서 일어나는 작업의 순서에 대해 어떤 보장도 할 수 없다.
- 즉 양쪽 스레드의 작업 사이에는 미리 발생 관계가 전혀 존재하지 않는다.

### 16.1.4 동기화 피기백
- 코드의 실행 순서를 정하는 면에서 미리 발생 규칙이 갖고 있는 능력의 수준 때문에 현재 사용중인 동기화 기법의 가시성에 얹혀가는 방법, 즉 피기백하는 방법도 있다.
- 다시 말해 락으로 보호대 있지 않은 변수에 접근해 사용하는 순서를 정의할 때, 모니터 락이나 volitile 변수 규칙과 같은 여러 가지 순서 규칙에 미리 발생 규칙을 함께 적용해 순서를 정의하는 방법을 말한다.
- 이런 기법은 명령이 나열된 순서에 굉장히 민감하며 따라서 오류가 발생하기 쉽다.
- 이런 방법은 ReentrantLock과 같이 성능에 중요한 영향을 미치는 클래스에서 성능을 떨어뜨릴 수 있는 아주 작은 요인까지 완벽하게 제거해야 하는 상황이 오기 전까지는 사용하지 않는 편이 좋다.
- FutureTask 클래스에서 protected 로 구현하고 있는 AQS의 메소드를 보면 이와 같은 피기백 방법을 사용하는 모습을 볼 수 있다.
- AQS는 FutureTask가 맡은 작업의 진행 상태, 즉 실행 중, 완료, 취소 등의 여부를 정수형으로 보관한다.
- FutureTask는 작업의 상태 외에도 완료된 작업의 결과 값 등을 보관한다. 한쪽 스레드에서 set 메소드를 사용해 실행한 결과를 보관하고 다른 스레드에서는 get 메소드를 호출해 결과 값을 가져가려고 한다고 가정해보면, set과 get 작업은 미리 발생 규칙으로 그 순서를 정의할 수 있다.
- 즉 결과 값을 보관하는 변수를 volatile로 선언하는 것으로도 원하는 결과를 얻을 수 있겠지만, 기존의 동기화 방법을 잘 활용하면 훨씬 적은 자원으로 동이란 결과를 얻을 수 있다.
- FutureTask는 미리 발생 규칙에 따라 tryReleasedShared 메소드의 작업이 tryAcquireShared 메소드보다 항상 먼저 실행되도록, 즉 tryReleasedShared 메소드에서 항상 tryAcquireShared 메소드가 읽어가는 변수에 쓰는 방법으로 세심하게 구현돼 있다.
- 작업의 결과를 보관하거나 읽어가는 기능을 담당하는 innerSet 메소드와 innerGet 메소드의 코드가 예제 16.2에 소개돼 있다.
- 예제 16.2 동기화 피기백 방법을 사용하고 있는 FutureTask 내부 클래스
~~~java
public class Example16_2<V> {
    private final class Sync extends AbstractQueuedSynchronizer {
        private static final int RUNNING = 1, RAN = 2, CANCELLED = 4;
        private V result;
        private Exception exception;
        
        void innserSet(V v) {
            while (true) {
                int s = getState();
                if(ranOrCancelled(s)) {
                    return;
                }
                if(compareAndSetState(s, RAN)) {
                    break;
                }
            }
            result = v;
            releaseShared(0);
            done();
        }
        
        V innerGet() throws InterruptedException, ExecutionException {
            acquireSharedInterruptibly(0);
            if(getState() == CANCELLED) {
                throw new CancellationException();
            }
            if(exception != null) {
                throw new ExecutionException(exception);
            }
            return result;
        }
    }
}
~~~
- innserSet 메소드는 releasedShared 메소드를 호출하기 전에 result변수에 값을 보관하고, innerGet메소드는 acquireShared 메소드를 호출한 이후에 result 값을 읽어간다.
- 이처럼 volatie 변수 규칙에 프로그램 순서 규칙을 함께 적용함으로써 innerSet 메소드에서 reulst 변수에 값을 쓰는 일이 innerGet 메소드에서 result 변수의 값을 읽는 작업보다 반드시 먼저 발생하도록 조절하고 있다.
- 이와 같은 방법은 X라는 객체의 값을 공개 할 때 미리 발생 규칙을 따로 적용하기보다는, 다른 목적으로 만들어 사용하고 있는 미리 발생 순서 규칙을 X라는 객체의 가시성을 확보하는 데도 함께 사용하기 때문에 피기백이라고 부른다.
- FutureTask 클래스에서 사용하는 것과 같은 종류의 피기백 방법은 오류가 발생할 가능성이 크기 때문에 대충 사용해서는 안된다.
- 어쨋거나 특정 클래스가 자체적인 명세의 일부로써 메소드 사이에서 미리 발생 규칙을 사용하는 경우와 같은 부분에서는 피기백 방법이 딱 들어맞는 상황도 있다.
  - ex : BlockingQueue 내부에서 적절한 동기화 구조를 통해 큐에서 값을 뽑아내는 작업이 큐에 값을 넣는 작업보다 미리 발생하도록 보장하기 때문에 안전한 공개 상태에서 동작할 수 있다.
- JDK 라이브러리에 들어 있는 클래스 가운데 미리 발생 관계를 보장하고 있는 클래스로는 다음과 같은 것들이 있다.
  - 스레드 안전한 컬렉션 클래스에 값을 넣는 일은 해당 컬렉션 클래스에서 값을 뽑아내는 일보다 반드시 미리 발생한다.
  - CountDownLatch 클래스에서 카운터를 빼는 작업은 await에서 대기하던 메소드가 리턴되는 작업보다 반드시 미리 발생한다.
  - Semaphore에서 퍼밋을 해제하는 작업은 동일한 Semaphore에서 퍼밋을 확보하는 작업보다 반드시 미리 발생한다.
  - Future 인스턴스에서 실행하는 작업은 해당하는 Future인스턴스의 get 메소드가 리턴되기 전에 반드시 미리 발생한다.
  - Executor 인스턴스에 Runnable 이나 Callable 을 등록하는 작업은 해당 Runnable이나 Callable의 작업이 시작하기 전에 미리 발생한다.
  - CyclickBarrier나 Exchange 클래스에서 스레드가 도착하는 일은 동일한 배리어나 교환 포인트에서 다른 스레드가 풀려나는 일보다 미리 발생한다. CyclickBarrier에서 배리어 동작을 사용하고 있었다면, 배리어에 도착하는 일이 배리어 동작보다 반드시 미리 발생하고, 배리어 동작은 또한 해당 배리어에서 다른 스레드가 풀려나기 전에 반드시 미리 발생한다.

## 16.2 안전한 공개
- 앞서 3장에서는 객체를 어떻게 하면 안전하게 공개할 수 있고, 반대로 어떻게 하면 잘못 공개될 수 있는지에 대해서 알아봤다.
- 3장에서 소개했던 안전한 공개 기법은 JMM이 보장하는 몇 가지 항목을 기반으로 안전성을 확보하고 있다.
- 다시 말해 객체가 안전하지 않게 공개되는 이유는 공유 객체를 공개하는 작업과 다른 스레드에서 공개된 객체를 사용하는 작업 간의 미리 발생 관계를 제대로 적용하지 못했기 때문이다.

### 16.2.1 안전하지 못한 공개
- 안전한 공개라는 용어는 객체를 공개하는 작업이 다른 스레드에서 해당 객체에 대한 참조를 가져다 사용하는 작업보다 미리 발생하도록 만들어져 있기 때문에 공개된 객체가 다른 스레드에게 올바른 상태로 보인다는 것을 뜻한다.
- 스레드 A에서 객체 X를 BlockingQueue에 추가하고 다른 스레드에서 큐의 내용을 변경하지 않으면, 객체 X를 스레드 B에서 뽑아냈을 때, 스레드 B는 스레드 A가 큐에 넣었떤 그 상태 그대로의 객체를 사용할 수 있다.
- BlockingQueue 클래스는 내부적으로 put작업이 take 작업보다 항상 미리 발생하도록 충분히 동기화돼 있기 때문이다.
- 이와 비슷하게 락으로 보호돼 있는 공유된 변수나 공유된 volatile 변수를 사용할 때는 읽기 작업과 쓰기 작업에 대한 미리 발생 관계가 항상 보장돼 있다.
- 이와 같이 미리 발생 관계가 보장된다는 사실은 안전한 공개에 의해 보장되는 가시성과 실행 순서보다 더 강력한 힘을 갖고 있다.
- X 객체가 스레드 A와 B에서 안전하게 공개됐다면, 안전한 공개라는 방법을 통해 X객체의 상태에 대한 가시성은 보장받을 수 있지만 스레드 A가 사용했던 변수의 상태에 대해서는 아무런 보장을 하지 못한다.
- 하지만 스레드 A에서 X를 큐에 추가하는 일이 스레드 B가 X를 큐에서 꺼내는 작업보다 미리 발생한다고 하면, 스레드 B에서는 X를 스레드 A가 큐에 추가할 시점과 동일한 상태로 볼 수 있을 뿐만 아니라 스레드 A가 큐에 넣기 전에 처리했던 모든 작업을 전부 볼 수 있다.
- JMM은 이미 강력한 미리 발생 규칙에 따라 동작하고 있음에도 불구하고 왜 지금까지 @GuardedBy와 안전한 공개기법에 초점을 맞춰왔을까? 일반적으로 프로그램을 작성할 때는 개별적으로 메모리에 쓰기 작업이 일어난 이후에 가시성을 놓고 안전성을 논하기보다는 객체의 소유권을 넘겨주고 공개하는 작업이 훨씬 적합하기 때문이다.
- 즉 미리 발생 규칙은 개별적인 메모리 작업의 수준에서 일어나는 순서의 문제를 다룬다.
- 말하자면 동기화 기법에 대한 어셈블리 언어
- 반대로 안전한 공개 기법은 일반적인 코드를 작성할 때와 비슷한 수준에서 동작하는 동기화 기법이다.

### 16.2.3 안전한 초기화를 위한 구문
