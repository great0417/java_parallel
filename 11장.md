# 11 성능, 확장성
- 스레드를 사용하는 가장 큰 목적 = 성능을 높임
- 스레드를 사용하면 시스템의 자원을 훨씬 효율적으로 활용할 수 있고, 애플리케이션으로 하여금 시스템이 갖고 있는 능력을 최대한 사용하게 할 수 있고 응답속도도 향상시킬 수 있다.
- 11장에서는 병렬프로그램의 성능을 분석하고, 모니터링하고, 그 결과로 성능을 향상시킬 수 있는 방법에 대해 알아본다.
- 대부분 애플리케이션의 내부 구조를 복잡하게 만들어야 하는 경우가 많고, 안전성과 활동성에 문제가 생길 가능성도 많다.
    - 성능을 높이기 위해 적용한 프로그래밍 기법이 역효과를 가져올 수도 있다.
    - 성능때문에 안전성을 해칠 수는 없다.
- 일단 프로그램이 정상적으로 동작하도록 만들고 난 다음 프로그램이 빠르게 동작하는 편이 낫다.

## 11.1 성능에 대해
- 성능을 높이는 것 = 더 적은 자원을 사용하면서 더 많은 일을 하도록 한다
    - 자원 -> 처리해야 할 작업이 있을 때 CPU, 메모리, 네트워크 속도, 디스크 속도, 데이터베이스 처리 속도, 디스크 용량 가운데 하나
- 자원중에 항상 모자라는 부분이 발생할 것이다.
- 작업을 실행할 때 충분하지 못한 특정 자원 때문ㅇ ㅔ성능이 떨어지는 현상이 나타난다면, 작업의 성능이 해당 자원에 좌우된다고 한다.
- 적절한 작업 비용을 스레드에 효율적으로 적용한다면 성능이나 응답성이 높아지고 처리 용량도 커지는 장점이 있다.
- 그러나 잘못 설계된 병렬 애플리케이션은 순차적으로 작업을 처리하는 프로그램보다 느리게 동작하는 경우도 간혹 생긴다.
- 더 나은 성능을 목표로 프로그램이 병렬로 동작하게 할 경우 생각해야할 2가지
    - 1. 프로그램이 확보할 수 있는 모든 자원을 최대한 활용
    - 2. 남는 자원이 생길 때마다 그 자원 역시 최대한 활용
### 11.1.1 성능 대 확장성
- 애플리케이션의 성능은 여러가지 측변에서 자료를 수집해 측정 가능
    - 서비스 시간, 대기 시간(얼마나 빠르냐), 처리량, 용량(얼마나 많은 양을 하냐), 효율성, 확장성(CPU, 메모리, 디스크, I/O 장치 등의 추가적인 정비를 사용해 처리량이나 용량을 얼마나 쉽게 키울 수 있냐) 등
- 병렬 프로그램 환경에서 확장성을 충분히 가질 수 있도록 애플리케이션을 설계하고 튜닝하는 방법은 기존에 해오던 일반적인 성능 최적화 방법과 다른 부분이 많다.
- 성능을 높이기 위해서 튜닝 작업을 하는 경우에 그 목적은 동일한 일을 더 적은 노력으로 하고자 하는것 (O(n^2) -> O(n log n)) 
- 성능에서 얼마나 빠르게와 얼마나 많이는 완전히 다른 뜻을 가지며, 심지어 서로 화합할 수 없는 상황도 생긴다. 
- 더 높은 확장성을 확보하거나 하드웨어의 자원을 더 많이 활용하도록 하다 보면, 앞서 큰 작업 하나를 작은 여러 개의 작업으로 분할해 처리하는 것처럼 개별 작업을 처리할 때 필요한 작업의 양을 늘리는 결과를 얻을 때가 많다.
- 단일 스레드 애플리케이션에서 사용하던 성능 개선 방안은 대부분 확장성의 측면에서 효과적이지 않다.
- 3-티어 모델을 보면 시스템의 확장성을 높이도록 변경하려 할 때 성능의 측면에서 얼마나 많은 소해를 보는 경우가 많은지 쉽게 알 수 있다.
- 프리젠테이션, 비지니스 로직, 스로티지의 세 가지 부분이 하나로 통합돼 있는 단일 애플리케이션을 다중 티어 애플리케이션과 비교해 보면, 다중 티어 애플리케이션이 웬만큼 잘 만들어져있다 하더라도 별다른 튜닝을 하지 않은 단일 애플리케이션의 성능이 훨씬 나을 가능성이 ㅁ낳다.
    - 단일 구조 애플리케이션은 서로 다른 티어 간에 주고받는 도중에 발생하는 네트워크 시간 지연 현상도 없을 것이고, 연산 작업을 서로 다른 추상적인 계층을 통과시켜가며 처리하는데 드는 부하가 적기 때문
- 하지만 단일 구조의 애플리케이션이 처리할 수 있었던 최대 부하를 넘어서는 작업량을 감당해야 하는 순간이 오면 문제는 심각.
- 서버 애플리케이션을 만들 때는 얼마나 빠르게라는 측면보다 얼마나 많이 라는 측면, 즉 확장성과 처리량과 용량이 훨씬 중요하다. 
- 11장에서는 단일 스레드 상황에서의 성능보다는 확장성을 중점적으로 다룬다.

### 11.1.2 성능 트레이드 오프 측정
- 공학적인 모든 선택의 순간에는 항상 트레이드 오프가 존재하기 마련.
- 강 위에 다리를 건설할 때 돔더 두꺼운 강판을 사용하면 다리를 수용할 수 있는 용량이 늘어나고 아전성도 높아지겠지만 건설 비용 역시 크게 증가.
- 소프트웨어 공학에서는 트레이트 오프에서 어떤 부분을 선택해야 할지를 결정하는데 필요한 정보가 그다지 충분하지 않다.
    - ex: 퀵소트 알고리즘은 대량의 자료를 정렬할 때 효율이 높지만, 자료의 양이 많지 않을 경우 버블 정렬 알고리즘이 훨씬 효율적이다.
- 프로그램을 작성하는 도중에 효율적인 정렬 기능을 구현해야 할 필요가 있따면, 먼저 정렬할 대상 데이터의 규모가 어느 정도인지 먼저 알아낼 필요가 있고, 평균적인 처리 시간을 중점적으로 최적화할지, 최악의 경우에 중점을 둬야 할지, 아니면 예측성에 중점을 둬야 하는지에 대한 결정을 내릴 수 있도록 추가적인 자료를 뽑아내는 것도 좋다.
- 하지만 일반적으로 정렬 기능을 라이브러리로 구현하는 입장에서 알 수 있는 정보는 굉장히 제한적이다.
- 그러므로 최적화 기법을 너무 이른 시점에 적용하지 말아야 한다. 일단 제대로 동작하게 만들고 난 다음에 빠르게 동작하도록 최적화해야 하며, 예상한 것보다 심각하게 성능이 떨어지는 경우에만 최적화 기법을 적용하는 것으로도 충분하다.
- 공학적인 결정을 내려야 하는 시저에는 어떤 효과를 얻고자 할 때 다른 비용을 지출해야만 할 수 있고, 또 어떤 경우에는 안전성을 확보하기 위해 비용을 지불해야 할 수도 있다.
- 성능을 높이기 위한 대부분의 결정 사항에는 다양한 변수가 관여하곤 하고 처한 상황에 따라 결정 사항이 크게 달라진다. 특정 방법이 다른 방법보다 빠르다 라고 말하기 전에 고려해야 할 사항
    - 1. 빠르다란 단어가 무엇을 의마하는가?
    - 2. 어떤 조건을 갖춰야 할 때 이 방법이 실제로 빠르게 동작할 것인가? 부하가 적을 때? 부하가 걸릴 대? 데이터가 많을 때? 데이터가 적을 때? 이런 질문에 대한 대답에 명확한 수치를 보여줄 수 있는가?
    - 3. 위의 조건에 해당하는 경우가 얼마나 많이 발생하는가? 이런 질문에 대한 대답에 명확한 수치를 보여줄 수 있는가?
    - 4. 조건이 달라지는 다른 상황에서도 같은 코드를 사용할 수 있는가?
    - 5. 이 방법으로 성능을 개선하고자 할 때, 숨겨진 비용, 즉 개발 비용이나 유지 보수 비용이 증가하는 부분이 어느 정도인지? 그런 부분을 감수하면서까지 성능 개선 작업을 해야 하는가?
- 이와 같은 판단 기준은 성능과 관련된 설계와 개발에 대한 결정사항이라면 어디든 적용해 볼 수 있지다.
- 병렬 프로그램에서 발생하는 오류의 가장 큰 원인 = 성능을 높이려는 여러 가지 기법
    - 단순한 동기화 방법이 너무 느리다고 전제하고, 직접적인 동기화 구문을 덜 사용할 수 있게 해주고 아주 훌륭한 모습을 갖추긴 했지만 위험성을 많이 내포하고 있는 여러가지 방법이 공개되어 있으며 이런 방법이 동기화 구문과 관련된 여러가지 규칙을 사용하지 않아도 된다는 핑곗거리로 자주 소개되곤 한다.
- 버그의 원인이 될 가능성이 조금이라도 있는 위험도 높은 코드는 매우 주의 깊게 살펴봐야 한다.
- 성능을 높이기 위해 안전성을 떨어뜨리는 것은 최악의 상황, 결국 안전성과 성능 둘 다 놓치게 된다.
- 성능을 튜닝하는 모든 과정에서 항상 성능 목표에 대한 명확한 요구사항이 있어야 하며 그래야 어느 부분을 튜닝하고 어느 시점에서 튜닝을 그만둬야 하는지 판단할 수 있다.
- 성능 튜닝 작업을 한 다음에는 반드시 원하는 목표치를 달성했는지 다시 측정 값을 뽑아내야 한다.
   - 추측하지 말고 실제로 측정해보라.
- 시장에 나온 성능 측정용 제품을 보면 소프트웨어의 성능을 세밀하게 측정해주고, 병목이 어디에 있는지 눈으로 직접 볼 수 있다.

## 11.2 암달의 법칙
- 일부 작업은 자원을 많이 투입하면 더 빨리 처리할 수 있다. 
    - ex : 곡식을 추수할 경우 사람 많으면 추수 작업 빠릴 끝남.
- 어떤 작업은 기본적으로 순차적으로 처리해야 한다.
    - ex : 곡식이 자라는 과장은 작업인력이 많다고 빠르게 할 수 있는게 아님
- 프로그램을 작성할 때 스레드를 사용하려는 주된 이유가 멀티 프로세서의 성능을 최대한 활용하는 것이라면, 프로그램에서 처리하는 내용이 병렬화를 할 수 있는 일인지를 확실히 해둬야 하고, 작업을 병렬화 했을 때 그 가능성을 최대한 활용할 수 있어야 한다.
- 대부분의 병렬프로그램에는 병렬화 할 수 있는 작업과 순차적으로 처리해야 하는 작업이 뒤섞인 단위 작업의 덩어리를 갖고 있다. 암달의 법칙을 사용하면 예측값 얻을 수 있다.
- 암달의 법칙 : 순차적으로 실행해야 하는 작업의 비율이 F, 하드웨어에 꽂혀있는 프로세서의 개수 N일 경우 
    - 속도증가량 <= 1 / F + ((1 -F) / N)
- N이 무한대까지 증가할 수록 속도 즈가량은 1/F까지 증가. 1/F 라는 속도 증가량은 순차적으로 진행돼야 하는 부분에이 전체 작업의 50%를 차지한다고 할 때 프로세서를 아무리 많이 꽂는다 해도 겨우 두배 빨리진다는 결과
- 순차적으로 실행해야 하는 부분이 전체의 10%에 해당한다면 최고 10배까지 속도를 증가시킬수 있다고 예측할 수 있다. 
- 암달의 법칙을 활용하면 작업을 순차적으로 처리하는 부분이 많아질 때 느려지는 정도가 얼마만큼인지를 수치화할 수 있다. 
    - 하드웨어에 CPu가 10개 꽂혀 있을 때 10%의 순차 작업을 갖고 있는 프로그램은 최고 5.3배 만큼의 속도를 증가시킬 수 있다.
    - 같은 상황에서 CPu를 100개를 꽂는다면 최대 9.2배까지 속도가 증가할 것이라고 예상할 수 있다.
    - 그러나보니 속도를 10배까지 증가시키려면 CPu의 활용도가 비효율적으로 떨어질 수 밖에 없다.
- 암달의 법칙에 따르면 프로세서의 개수가 증가하면 증가할수록 순차적으로 실행해야 하는 부분이 아주 조금이라도 늘어나면 프로세서 개수에 비해 얻을 수 있는 속도 증가량이 크게 떨어진다.
- 멀티프로세서 시스템에서 애플리케이션의 속도를 예측해보려면 순차적으로 처리해야 하는 작업이 얼마나 되는지를 살펴봐야 한다.
- 예제 11.1 작업 큐에 대한 순차적인 접근
~~~java
public class WorkerThread extends Thread {
    private final BlockingQueue<Runnable> queue;
    
    public WorkerThread(BlockingQueue<Runnable> queue) {
        this.queue = queue;
    }

    @Override
    public void run() {
        while (true) {
            try {
                Runnable task = queue.take();
                task.run();
            } catch (InterruptedException e) {
                break; /* 스레드를 종료시킨다. */
            }
        }
    }
}
~~~
- 예제 11.1의 코드에서 doWork 메소드를(? 어디?) N개의 스레드가 동시에 실행한다고 해보자. doWork 메소드는 공유돼 있는 작업 큐에 쌓인 작업을 가져와서 처리하게 되어있다. 그리고 각 작업은 다른 스레드나 다른 작업과 아무런 고나련 없이 독립적으로 동작한다고 가정하자. 
- 내부를 잘 살펴보면 순차적으로 처리해야만 하는 부분이 있다. 바로 작업 큐에서 작업을 하나씩 뽑아 내는 부분이다.
- 여러 스레드가 동시 다발적으로 큐를 사용하려 할 때 안전성을 잃지 않도록 적당한 양의 동기화 작업이 선행돼야 한다. 
    - ex : 큐의 상태를 안정적으로 유지하고자 락을 사용했다면 특정 스레드가 큐에서 작업을 하나 뽑아내는 그 시점에, 역시 큐에서 작업을 가져가고자 하는 다른 모든 스레드는 큐를 독점적으로 사용할 수 있을때까지 대기해야만 한다. 따라서 작업 큐와 관련된 부분에서는 프로그램이 순차적으로 처리될 수 밖에 없다.
- 단일 작업 하나가 실행되는 시간에는 Runnable을 실행하는데 드는 시간뿐만 아니라 공유돼 있는 작업 큐에서 작업을 뽑아내는데 필요한 시간도 포함돼 있다.
- 작업 큐로 LinkedBlockingQueue를 사용하고 있다면, 큐에서 작업을 뽑아낼 때 대기하는 시간이 동기화된 LinkedList를 사용할 때보다 훨씬 적게 든다. 데이터를 한 군데에 공유해두고 사용하는 모든 부분은 항상 순차적으로 처리해야 한다.
- 작업의 처리 결과를 취합하는 부분도 마찬가지이다.
- 모든 병렬 프로그램에는 항상 순차적으로 실행돼야만 하는 부분이 존재한다. 만약 그런 부분이 없다고 생각한다면 프로그램 코드를 다시 한번 들여다보라.

### 11.2.1 예제 : 프레임워크 내부에 감쳐줘있는 순차적 실행 구조
- 애플리케이션의 내부 구조에 순차적으로 처리해야 하는 구조가 어떻게 숨겨져 있는지를 알아보려면 스레드 개수를 증가시킬 때마다 성능이 얼마나 빨라지는지를 기록해두고 추측 가능하다.
- 작업을 처리하는 단계에는 단순하게 스레드 내부에서만 동작하는 연산 과정이 진행된다. 큐가 비었다는 사실을 스레드가 알게 되면, 해당 스레드는 큐에 일정 개수의 작업을 추가해서 작업을 가져가려는 다른 스레드가 계쏙해서 실행할 수 있도록 했다.
- ConcurrentLinkedQueue  클래스의 처리량은 계속해서 증가하다가 프로세서의 개수에 해당하는 수치에 다다르면 유지
- 동기화된 LinkedList는 3개까지는 증가하다가 그 이후에는 동기화 관련 부하가 늘어나서 성능이 떨어진다.
- 동기화된 LinkedList 클래스는 전체 큐의 상태를 하나의 락으로 동기화하며, 따라서 offer나 remove메소드를 호출하는 동안 전체 큐가 모두 락에 걸린다.
- 하지만 ConcurrentLinkedQueue 클래스는 정교한 큐 알고리즘사용. 즉 개별 포인터에 대한 업데이트 연산만 순차적으로 처리하면 된다.

### 11.2.2 정상적인 암달의 법칙 적용 방법
- 암달의 법칙을 사용하면 프로그램 내부에서 순차적으로 처리돼야만 하는 부분의 비율을 알고 있을 때, 하드웨어를 추가함에 따라 얼마만큼 처리 속도가 증가할 것인지를 수치화해서 추측 가능
- 대부분의 경우 멀티프로세서 시스템이라 하면 두 개나 네 개의 프로세서가 달린 경우를 생각하고, 자금의 여유가 있다면 잘해야 열 몇개의 프로세서를 장착하는 정도밖에 생각하지 못하낟.
- 하지만 멀티코어 CPU가 대중적으로 많이 보급되면서 이제는 수백개에서 수천개의 프로세서를 장착한 시스템을 어렵지 않게 생각하게 됐다.
- 수 백개 또는 수 천개의 프로세서가 동작하는 상황까지 가정한 상태에서 프로그램의 알고리즘을 평가한다면, 어느 시점쯤에서 확장성의 한계가 나타날것인지를 예측해 볼 수 있다.
    - 락의 적용 범위를 줄이는 방법, 즉 락분할 과 락 스트라이핑에 대해서 알아볼 것이다.
- 암달의 법칙에서 바라보면 락을 두 개로 분할하는 정도로는 다수의 프로세서를 충분히 활용하기 어렵다는 결론을 얻을 수 있다. 
- 하지만 락 스트라이핑방법을 사용할 때는 프로세서의 수가 늘어남에 따라 분할 개수를 같이 증가시킬 수 있기 때문에 확장성을 얻을 수 있는 훨씬 믿을만한 방법이라고 할 수 있다.

## 11.3 스레드와 비용
- 스레드를 사용하는 경우 병렬로 실행함으로써 얻을 수 있는 이득이 병렬로 실행하느라 드는 비용을 넘어서야 성능을 향상시킬 수 있다.

### 11.3.1 컨텍스트 스위칭
- 메인 스레드 하나만 스케쥴링 한다고 하면, 메인스레드는 항상 실행될 것이다.
- 반대로 CPU 개수보다 실행중인 스레드의 개수가 많다고 하면, 운영체제가 특정 스레드의 실행 스케쥴을 선점하고 다른 스레드가 실행될 수 있도록 스케쥴을 잡는다.
- 이처럼 하나의 스레드가 실행되다가 다른 스레드가 실행되는 순간 컨텍스트 스위칭이 일어난다. 
    - 먼저 실행중인 스레드의 실행 상태를 보관해두고, 다음 번에 실행되기로 스케쥴된 다른 스레드의 실행 상태를 다시 읽어드린다.
- 컨텍스트 스위칭은 단숨에 공짜로 일어나는 일이 아니다. 스레드 스케줄링을 하려면 운영체제와 JVM 내부의 공용 자료 구조를 다뤄야 한다는 문제가 있다.
- 운영체제와 JVM 역시 프로그램 스레드가 사용하는 것과 같은 CPU를 함께 사용하고 있다. 따라서 운영체제나 JVM이 CPU를 많이 사용하면 할수록 실제 프로그램 스레드가 사용할 수 있는 CPU의 양이 줄어든다.
- 컨텍스트가 변경되면서 다른 스레드를 실행하려면 해당 스레드가 사용하던 데이터가 프로세서의 캐시 메모리에 들어 있지 않을 확률도 높다.
    - 그러면 캐시에서 찾이 못한 내용을 다른 저장소에서 찾아와야 하므로 느리게 실행된다
- 이런 경우에 대비하고자 대부분의 스레드 스케줄러는 실행 대기 중인 스레드가 밀려 있다고 해도, 현재 실행중인 스레드에게 최소한의 실행 시간을 보장해주는 정책을 취하고 있다.
- 그러면 컨텍스트 스위칭에 들어가는 시간과 비용을 나누는 효과를 볼 수 있고, 그 결과 인터럽트 받지 않고 실행할 수 있는 최소한의 시간을 보장받기 때문에 전체적으로 성능이 향상되는 효과를 볼 수 있다.
- 스레드가 실행하다가 락을 확보하기 위해 대기하기 시작하면, 일반적으로 JVM은 해당 스레드를 일시적으로 정지시키고 다른 스레드가 실행되도록 한다. 
- 특정 스레드가 빈번하게 대기 상태에 들어간다고 하면 스레드별로 할당된 최소 실행 시간조차 사용하지 못한 경우도 있다.
- 대기상태에 들어가는 연산을 많이 사용하는 프로그램은 CPu를 주로 활용하는 프로그램보다 컨텍스트 스위칭 횟수가 훨씬 많아지고, 따라서 스케줄링 부하가 늘어나면서 전체적인 처리량이 줄어든다.
- 컨텍스트 스위칭에 필요한 부하와 비용은 플랫폼마다 다르지만 대략 살펴본 바에 따르면 최근 사용되는 프로세서상에서 5000~10000 클럭 사이클 또는 수 마이크로 초 동안의 시간을 소모한다고 알려져 있다.
- 유닉스 시스템의 vmstat 명령이나, 윈도우 시스템의 perform 유틸리티를 사용하면 컨텍스트 스위칭이 일어난 횟수를 확인할 수 있으며 커널 수준에서 얼마만큼의 시간을 소모했는지 알 수 있다.
- 커널 활용도가 10%가 넘는 높은 값을 갖고 있다면 스케줄링에 부하가 걸린다는 의미이며, 아마도 애플리케이션 내부의 I/O 작업이나 락 관련 동기화 부분 때문에 대기 상태에 들어가는 부분이 원인일 가능성이 높다.

### 11.3.2 메모리 동기화